{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing libs - metrics,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catalyst\n",
    "!pip install albumentations\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "import catalyst\n",
    "from catalyst import dl\n",
    "from catalyst.utils import set_global_seed\n",
    "from catalyst import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from catalyst.utils import (\n",
    "    create_dataset, create_dataframe, get_dataset_labeling, map_dataframe\n",
    ")\n",
    "\n",
    "dataset = create_dataset(dirs=f\"Imagenette-comp/train/*\", extension=\"*.jpg\")\n",
    "df = create_dataframe(dataset, columns=[\"class\", \"filepath\"])\n",
    "\n",
    "tag_to_label = get_dataset_labeling(df, \"class\")\n",
    "class_names = [\n",
    "    name for name, id_ in sorted(tag_to_label.items(), key=lambda x: x[1])\n",
    "]\n",
    "\n",
    "df_with_labels = map_dataframe(\n",
    "    df, \n",
    "    tag_column=\"class\", \n",
    "    class_column=\"label\", \n",
    "    tag2class=tag_to_label, \n",
    "    verbose=False\n",
    ")\n",
    "df_with_labels.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.utils import split_dataframe_train_test\n",
    "\n",
    "train_data, valid_data = split_dataframe_train_test(\n",
    "    df_with_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_data, valid_data = (\n",
    "    train_data.to_dict(\"records\"),\n",
    "    valid_data.to_dict(\"records\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from catalyst.contrib.data.cv.reader import ImageReader\n",
    "from catalyst import utils\n",
    "from catalyst.data import ScalarReader, ReaderCompose\n",
    "\n",
    "num_classes = len(tag_to_label)\n",
    "\n",
    "open_fn = ReaderCompose(\n",
    "    [\n",
    "        ImageReader(\n",
    "            input_key=\"filepath\", output_key=\"features\", rootpath=\"Imagenette-comp/train\"\n",
    "        ),\n",
    "        ScalarReader(\n",
    "            input_key=\"label\",\n",
    "            output_key=\"targets\",\n",
    "            default_value=-1,\n",
    "            dtype=np.int64,\n",
    "        ),\n",
    "        ScalarReader(\n",
    "            input_key=\"label\",\n",
    "            output_key=\"targets_one_hot\",\n",
    "            default_value=-1,\n",
    "            dtype=np.int64,\n",
    "            one_hot_classes=num_classes,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2 as ToTensor\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "train_transform = albu.Compose([\n",
    "    albu.HorizontalFlip(p=0.5),\n",
    "    albu.LongestMaxSize(IMAGE_SIZE),\n",
    "    albu.PadIfNeeded(IMAGE_SIZE, IMAGE_SIZE, border_mode=0),\n",
    "    albu.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, p=0.3),\n",
    "    albu.Normalize(),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "valid_transform = albu.Compose([\n",
    "    albu.LongestMaxSize(IMAGE_SIZE),\n",
    "    albu.PadIfNeeded(IMAGE_SIZE, IMAGE_SIZE, border_mode=0),\n",
    "    albu.Normalize(),\n",
    "    ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from catalyst.data import Augmentor\n",
    "\n",
    "train_data_transform = Augmentor(\n",
    "    dict_key=\"features\", augment_fn=lambda x: train_transform(image=x)[\"image\"]\n",
    ")\n",
    "\n",
    "valid_data_transform = Augmentor(\n",
    "    dict_key=\"features\", augment_fn=lambda x: valid_transform(image=x)[\"image\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#batch_size = 256\n",
    "batch_size = 32\n",
    "\n",
    "num_workers = 1\n",
    "\n",
    "train_loader = utils.get_loader(\n",
    "    train_data,\n",
    "    open_fn=open_fn,\n",
    "    dict_transform=train_data_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    sampler=None,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_loader = utils.get_loader(\n",
    "    valid_data,\n",
    "    open_fn=open_fn,\n",
    "    dict_transform=valid_data_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False, \n",
    "    sampler=None,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "loaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"valid\": valid_loader\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, models\n",
    "\n",
    "class MyResNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyResNet50, self).__init__()\n",
    "        self.net = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Disable grad for all conv layers\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = False                \n",
    "        \n",
    "        # Create some additional layers for ResNet model\n",
    "        fc_inputs = self.net.fc.in_features\n",
    "        self.net.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(fc_inputs, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(128, 10),\n",
    "        )  \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, p=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                out_channels, out_channels, kernel_size=3, stride=1, padding=1\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        self.res = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride\n",
    "        )\n",
    "        self.output = nn.Sequential(nn.BatchNorm2d(out_channels), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = self.input(x)\n",
    "        res = self.res(x)\n",
    "        return self.output(res + input)\n",
    "\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, channels=3, in_features=64, num_classes=10, p=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels, in_features, kernel_size=7, stride=2, padding=3\n",
    "            ),\n",
    "            nn.BatchNorm2d(in_features),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.layer_0 = self._make_layer(in_features, 1)\n",
    "        self.layer_1 = self._make_layer(in_features)\n",
    "        in_features *= 2\n",
    "        self.layer_2 = self._make_layer(in_features)\n",
    "        in_features *= 2\n",
    "        self.layer_3 = self._make_layer(in_features)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2 * in_features, num_classes),\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_features, multiplier=2, p=0.1):\n",
    "        return nn.Sequential(\n",
    "            ResNetBlock(in_features, in_features * multiplier, stride=2, p=p),\n",
    "            ResNetBlock(\n",
    "                in_features * multiplier,\n",
    "                in_features * multiplier,\n",
    "                stride=1,\n",
    "                p=p,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.layer_0(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "class ClassificationRunner(SupervisedRunner):\n",
    "    def predict_batch(self, batch):\n",
    "        prediction = {\n",
    "            \"filepath\": batch[\"filepath\"],\n",
    "            \"log_probs\": self.model(batch[self.input_key].to(self.device))\n",
    "        }\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model = MyResNet50()\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner()\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=epochs,\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "# uncomment for extra metrics:\n",
    "#     callbacks=[\n",
    "#         dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", num_classes=10),\n",
    "#         dl.PrecisionRecallF1SupportCallback(\n",
    "#             input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "#         ),\n",
    "#         dl.AUCCallback(input_key=\"logits\", target_key=\"targets\"),\n",
    "#         # catalyst[ml] required ``pip install catalyst[ml]``\n",
    "#         dl.ConfusionMatrixCallback(\n",
    "#             input_key=\"logits\", target_key=\"targets\", num_classes=num_classes\n",
    "#         ),\n",
    "#     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##with metrix - json\n",
    "'''\n",
    "runner = ClassificationRunner(input_key=\"features\", target_key=\"targets\",output_key=\"logits\",loss_key=\"loss\")\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    loaders=loaders,\n",
    "    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_epochs=10,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    "    callbacks={\n",
    "        \"optimizer\": dl.OptimizerCallback(\n",
    "            metric_key=\"loss\", accumulation_steps=1, grad_clip_params=None,\n",
    "        ),\n",
    "        \"criterion\": dl.CriterionCallback(\n",
    "            input_key=\"targets\", target_key=\"logits\", metric_key=\"loss\",\n",
    "        ),\n",
    "        \"accuracy\": dl.AccuracyCallback(num_classes=10,input_key=\"logits\", target_key=\"targets\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "runner = dl.SupervisedRunner(\n",
    "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n",
    ")\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=1,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk_args=(1, 3, 5)),\n",
    "        dl.PrecisionRecallF1SupportCallback(\n",
    "            input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "        ),\n",
    "    ],\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    ")\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "submission = {\"Id\": [], \"Category\": []}\n",
    "model.eval()\n",
    "\n",
    "test_dataset = create_dataset(dirs=f\"Imagenette-comp/test/\", extension=\"*.jpg\")\n",
    "test_data = list({\"filepath\": filepath} for filepath in test_dataset[\"test\"])\n",
    "\n",
    "test_open_fn = ReaderCompose(\n",
    "    [\n",
    "        ImageReader(\n",
    "            input_key=\"filepath\", output_key=\"features\", rootpath=\"\"\n",
    "        ),\n",
    "        ScalarReader(\n",
    "            input_key=\"filepath\",\n",
    "            output_key=\"filepath\",\n",
    "            default_value=\"\",\n",
    "            dtype=str,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_loader = utils.get_loader(\n",
    "    test_data,\n",
    "    open_fn=test_open_fn,\n",
    "    dict_transform=valid_data_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    sampler=None,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "for prediction in runner.predict_loader(loader=test_loader):\n",
    "    prediction[\"labels\"] = [class_names[c] for c in torch.max(prediction[\"log_probs\"], axis=1)[1]]\n",
    "    submission[\"Id\"].extend(f.split(\"/\")[4].split(\".\")[0] for f in prediction[\"filepath\"])\n",
    "    submission[\"Category\"].extend(prediction[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(submission).to_csv(\"baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
